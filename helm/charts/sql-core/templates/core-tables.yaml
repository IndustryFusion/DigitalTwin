---
apiVersion: industry-fusion.com/v1alpha2
kind: BeamSqlTable
metadata:
  name: alerts
spec:
  name: alerts
  connector: kafka
  fields:
    - 'resource': STRING
    - 'event': STRING
    - 'environment': STRING
    - 'service': ARRAY<STRING>
    - 'severity': STRING
    - 'customer': STRING
    - 'text': STRING
  kafka:
    topic: {{.Values.kafkaBridge.alerta.listenTopic}}
    properties:
      bootstrap.servers: {{.Values.kafka.bootstrapServer}}
    scan.startup.mode: latest-offset
  value:
    format: json
    json.fail-on-missing-field: false
    json.ignore-parse-errors: true
---
apiVersion: industry-fusion.com/v1alpha2
kind: BeamSqlTable
metadata:
  name: alerts-bulk
spec:
  name: alerts_bulk
  connector: upsert-kafka
  fields:
    - 'resource': STRING
    - 'event': STRING
    - 'environment': STRING
    - 'service': ARRAY<STRING>
    - 'severity': STRING
    - 'customer': STRING
    - 'text': STRING
    - 'watermark': FOR ts AS ts - INTERVAL {{.Values.flink.alertDelay | squote}} SECONDS
    - 'ts': TIMESTAMP(3) METADATA FROM 'timestamp' VIRTUAL
  kafka:
    topic: {{.Values.kafkaBridge.alerta.bulkTopic}}
    properties:
      bootstrap.servers: {{.Values.kafka.bootstrapServer}}
    key.format: json
  value:
    format: json
    json.fail-on-missing-field: false
    json.ignore-parse-errors: true
  primaryKey: [resource, event]
---
apiVersion: industry-fusion.com/v1alpha2
kind: BeamSqlTable
metadata:
  name: ngsild-updates
spec:
  name: ngsild_updates
  connector: kafka
  fields:
    - 'op': STRING
    - 'overwriteOrReplace': Boolean
    - 'noForward': Boolean
    - 'entities': STRING
  kafka:
    topic: {{.Values.kafkaBridge.ngsildUpdates.listenTopic}}
    properties:
      bootstrap.servers: {{.Values.kafka.bootstrapServer}}
    scan.startup.mode: latest-offset
  value:
    format: json
    json.fail-on-missing-field: false
    json.ignore-parse-errors: true
---
apiVersion: industry-fusion.com/v1alpha2
kind: BeamSqlTable
metadata:
  name: attributes
spec:
  name: attributes
  connector: kafka
  fields:
    - id: STRING
    - parentId: STRING
    - entityId: STRING
    - name: STRING
    - nodeType: STRING
    - valueType: STRING
    - type: STRING
    - attributeValue: STRING
    - datasetId: STRING
    - unitCode: STRING
    - lang: STRING
    - deleted: BOOLEAN
    - synced: BOOLEAN
    - 'ts': TIMESTAMP(3) METADATA FROM 'timestamp' VIRTUAL
    - 'watermark': FOR ts AS ts
  kafka:
    topic: {{.Values.kafkaBridge.debezium.attributesTopic}}
    properties:
      bootstrap.servers: {{.Values.kafka.bootstrapServer}}
    scan.startup.mode: latest-offset
  value:
    format: json
    json.fail-on-missing-field: false
    json.ignore-parse-errors: true
---
apiVersion: industry-fusion.com/v1alpha2
kind: BeamSqlTable
metadata:
  name: attributes-writeback
spec:
  name: attributes_writeback
  connector: upsert-kafka
  fields:
  - id: STRING
  - parentId: STRING
  - entityId: STRING
  - name: STRING
  - nodeType: STRING
  - valueType: STRING
  - type: STRING
  - attributeValue: STRING
  - datasetId: STRING
  - unitCode: STRING
  - lang: STRING
  - deleted: BOOLEAN
  - synced: BOOLEAN
  kafka:
    topic: iff.ngsild.attributes
    properties:
      bootstrap.servers: my-cluster-kafka-bootstrap:9092
    key.format: json
  value:
    format: json
    json.fail-on-missing-field: false
    json.ignore-parse-errors: true
  primaryKey:
  - id
  - datasetId
---
apiVersion: industry-fusion.com/v1alpha1
kind: BeamSqlView
metadata:
  name: attributes-view
spec:
  name: attributes_view
  sqlstatement: |
    SELECT id, parentId, entityId, name, nodeType, valueType, `type`,
            `attributeValue`,
            `datasetId`,
            `unitCode`,
            `lang`,
            `deleted`,
            `synced`,
           `ts`
    FROM (
      SELECT *,
      ROW_NUMBER() OVER (PARTITION BY `id`, `datasetId`
         ORDER BY ts DESC) AS rownum
      FROM `attributes`)
      WHERE rownum = 1;
---
apiVersion: industry-fusion.com/v1alpha2
kind: BeamSqlTable
metadata:
  name: attributes-insert
spec:
  name: attributes_insert
  connector: upsert-kafka
  fields:
  - id: STRING
  - parentId: STRING
  - entityId: STRING
  - name: STRING
  - nodeType: STRING
  - valueType: STRING
  - type: STRING
  - attributeValue: STRING
  - datasetId: STRING
  - unitCode: STRING
  - lang: STRING
  - deleted: BOOLEAN
  - synced: BOOLEAN
  - ts: TIMESTAMP(3) METADATA FROM 'timestamp' VIRTUAL
  - watermark: FOR `ts` AS `ts`
  kafka:
    topic: iff.ngsild.attributes_insert
    properties:
      bootstrap.servers: my-cluster-kafka-bootstrap:9092
    key.format: json
  value:
    format: json
    json.fail-on-missing-field: false
    json.ignore-parse-errors: true
  primaryKey:
  - id
  - datasetId
---
apiVersion: industry-fusion.com/v1alpha2
kind: BeamSqlTable
metadata:
  name: attributes-insert-filter
spec:
  name: attributes_insert_filter
  connector: kafka
  fields:
  - id: STRING
  - parentId: STRING
  - entityId: STRING
  - name: STRING
  - nodeType: STRING
  - valueType: STRING
  - type: STRING
  - attributeValue: STRING
  - datasetId: STRING
  - unitCode: STRING
  - lang: STRING
  - deleted: BOOLEAN
  - synced: BOOLEAN
  - ts: TIMESTAMP(3) METADATA FROM 'timestamp'
  - watermark: FOR `ts` AS `ts`
  kafka:
    topic: iff.ngsild.attributes_insert
    properties:
      bootstrap.servers: my-cluster-kafka-bootstrap:9092
    scan.startup.mode: latest-offset
  value:
    format: json
    json.fail-on-missing-field: false
    json.ignore-parse-errors: true
---
apiVersion: industry-fusion.com/v1alpha1
kind: BeamSqlView
metadata:
  name: attributes-insert-view
spec:
  name: attributes_insert_view
  sqlstatement: |
    SELECT entityId, name, nodeType, valueType, `type`,
          `attributeValue`,
          `datasetId`,
          `unitCode`,
          `lang`,
          `deleted`,
          `synced`,
          `ts`
    FROM (
      SELECT *,
      ROW_NUMBER() OVER (PARTITION BY `id`, `datasetId`
         ORDER BY ts DESC) AS rownum
      FROM `attributes_insert_filter`)
      WHERE rownum = 1;