{{- $secret := "" }}
{{- if .Values.minio.enabled }}
  {{- $secret = (lookup "v1" "Secret" .Release.Namespace "minio-user") -}}
{{- end }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: flink-config
  namespace: {{ .Release.Namespace }}
  labels:
    app: flink
data:
  flink-conf.yaml: |+
    jobmanager.rpc.address: flink-jobmanager
    taskmanager.numberOfTaskSlots: 4
    pipeline.max-parallelism: 4
    blob.server.port: 6124
    jobmanager.rpc.port: 6123
    taskmanager.rpc.port: 6122

    queryable-state.proxy.ports: 6125
    jobmanager.memory.process.size: 1000m
    taskmanager.memory.process.size: 2500m

    s3.endpoint: {{ printf "%s://%s" .Values.s3.protocol .Values.s3.endpoint }}
    {{- if .Values.minio.enabled }}
    s3.path.style.access: true
    {{- end }}
    s3.access-key: {{ .Values.s3.userAccessKey }}
    {{ if $secret }}
    s3.secret-key: {{ $secret.data.CONSOLE_SECRET_KEY | b64dec }}
    {{ else }}
    s3.secret-key: {{ .Values.s3.userSecretKey }}
    {{ end }}
    state.backend.rocksdb.localdir: /tmp/rocksdb
    state.backend.rocksdb.log.level: INFO_LEVEL
    state.backend.rocksdb.log.max-file-size: 10MB
    state.backend.rocksdb.log.file-num: 10
    state.backend.rocksdb.log.dir: /tmp/rocksdb/logs
    state.backend.incremental: false

    # RocksDB metrics and Flamegraph. Enable these for debugging troubleshooting
    # rest.flamegraph.enabled: true
    # state.backend.rocksdb.metrics.actual-delayed-write-rate: true
    # state.backend.rocksdb.metrics.background-errors: true
    # state.backend.rocksdb.metrics.block-cache-capacity: true
    # state.backend.rocksdb.metrics.block-cache-hit: true
    # state.backend.rocksdb.metrics.block-cache-miss: true
    # state.backend.rocksdb.metrics.block-cache-pinned-usage: true
    # state.backend.rocksdb.metrics.block-cache-usage: true
    # state.backend.rocksdb.metrics.bytes-read: true
    # state.backend.rocksdb.metrics.bytes-written: true
    # state.backend.rocksdb.metrics.column-family-as-variable: true
    # state.backend.rocksdb.metrics.compaction-pending: true
    # state.backend.rocksdb.metrics.compaction-read-bytes: true
    # state.backend.rocksdb.metrics.compaction-write-bytes: true
    # state.backend.rocksdb.metrics.cur-size-active-mem-table: true
    # state.backend.rocksdb.metrics.cur-size-all-mem-tables: true
    # state.backend.rocksdb.metrics.estimate-live-data-size: true
    # state.backend.rocksdb.metrics.estimate-num-keys: true
    # state.backend.rocksdb.metrics.estimate-pending-compaction-bytes: true
    # state.backend.rocksdb.metrics.estimate-table-readers-mem: true
    # state.backend.rocksdb.metrics.is-write-stopped: true
    # state.backend.rocksdb.metrics.iter-bytes-read: true
    # state.backend.rocksdb.metrics.live-sst-files-size: true
    # state.backend.rocksdb.metrics.mem-table-flush-pending: true
    # state.backend.rocksdb.metrics.num-deletes-active-mem-table: true
    # state.backend.rocksdb.metrics.num-deletes-imm-mem-tables: true
    # state.backend.rocksdb.metrics.num-entries-active-mem-table: true
    # state.backend.rocksdb.metrics.num-entries-imm-mem-tables: true
    # state.backend.rocksdb.metrics.num-immutable-mem-table: true
    # state.backend.rocksdb.metrics.num-live-versions: true
    # state.backend.rocksdb.metrics.num-running-compactions: true
    # state.backend.rocksdb.metrics.num-running-flushes: true
    # state.backend.rocksdb.metrics.num-snapshots: true
    # state.backend.rocksdb.metrics.size-all-mem-tables: true
    # state.backend.rocksdb.metrics.stall-micros: true
    # state.backend.rocksdb.metrics.total-sst-files-size: true

    state.checkpoints.dir: s3://{{ .Values.flink.bucket }}/{{ .Values.flink.checkpointDir }}
    state.savepoints.dir: s3://{{ .Values.flink.bucket }}/{{ .Values.flink.savepointDir }}
    kubernetes.cluster-id: {{ .Values.flink.clusterId }}
    high-availability: kubernetes
    high-availability.storageDir: s3://{{ .Values.flink.bucket }}/{{ .Values.flink.haDir }}
    kubernetes.namespace: {{ .Release.Namespace }}
    restart-strategy: exponential-delay
    restart-strategy.exponential-delay.max-backoff: 2 min
    process.working-dir: /tmp/process
  log4j-console.properties: |+
    # This affects logging for both user code and Flink
    rootLogger.level = INFO
    rootLogger.appenderRef.console.ref = ConsoleAppender
    rootLogger.appenderRef.rolling.ref = RollingFileAppender

    # Uncomment this if you want to _only_ change Flink's logging
    #logger.flink.name = org.apache.flink
    #logger.flink.level = TRACE

    # The following lines keep the log level of common libraries/connectors on
    # log level INFO. The root logger does not override this. You have to manually
    # change the log levels here.
    logger.akka.name = akka
    logger.akka.level = INFO
    logger.kafka.name= org.apache.kafka
    logger.kafka.level = INFO
    logger.hadoop.name = org.apache.hadoop
    logger.hadoop.level = INFO
    logger.zookeeper.name = org.apache.zookeeper
    logger.zookeeper.level = INFO

    # Log all infos to the console
    appender.console.name = ConsoleAppender
    appender.console.type = CONSOLE
    appender.console.layout.type = PatternLayout
    appender.console.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n

    # Log all infos in the given rolling file
    appender.rolling.name = RollingFileAppender
    appender.rolling.type = RollingFile
    appender.rolling.append = false
    appender.rolling.fileName = ${sys:log.file}
    appender.rolling.filePattern = ${sys:log.file}.%i
    appender.rolling.layout.type = PatternLayout
    appender.rolling.layout.pattern = %d{yyyy-MM-dd HH:mm:ss,SSS} %-5p %-60c %x - %m%n
    appender.rolling.policies.type = Policies
    appender.rolling.policies.size.type = SizeBasedTriggeringPolicy
    appender.rolling.policies.size.size=100MB
    appender.rolling.strategy.type = DefaultRolloverStrategy
    appender.rolling.strategy.max = 10

    # Suppress the irrelevant (wrong) warnings from the Netty channel handler
    logger.netty.name = org.jboss.netty.channel.DefaultChannelPipeline
    logger.netty.level = OFF 